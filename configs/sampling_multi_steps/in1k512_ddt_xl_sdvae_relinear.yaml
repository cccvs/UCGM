output_dir: './outputs'

data:
  data_path: './buffers/data/sdvae_f8c4/train_512'
  fid_reference_file: './buffers/refs/in1k512_fid_ref.npz'
  image_size: 512
  num_classes: 1000
  num_workers: 8
  latent_norm: False
  latent_multiplier: 0.18215

vae:
  type: 'sdvae_ema_f8c4'
  downsample_ratio: 8

model:
  type: DDT-XL/2
  in_chans: 4

train:
  global_seed: 0

transport:
  type: ReLinear

# Note: This configuration achieves a state-of-the-art FID=1.18 with NFE=300, but was not included in our paper due to differences in cfg_scale and cfg_interval parameters compared to the DDT implementation (https://github.com/MCG-NJU/DDT). We plan to add these results in a future update to the paper as part of an additional exploration section.
sample: # Fid=1.18, NFE=300
  ckpt: "0000000.pt"
  type: UNI
  cfg_scale: 2.35
  cfg_interval: [0.24, 1.0]
  sampling_steps: 150
  stochast_ratio: 0.0
  extrapol_ratio: 0.48
  sampling_order: 1
  time_dist_ctrl: [1.14, 0.8, 1.1]
  rfba_gap_steps: [0.001, 0.001]
  per_batch_size: 25
  fid_sample_num: 50000


# # This result is reported in our paper.
# sample: # Fid=1.25, NFE=200
#   ckpt: "0000000.pt"
#   type: UNI
#   cfg_scale: 3.0
#   cfg_interval: [0.30, 1.00]
#   sampling_steps: 100
#   stochast_ratio: 0.0
#   extrapol_ratio: 0.32
#   sampling_order: 1
#   time_dist_ctrl: [1.17, 0.8, 1.1]
#   rfba_gap_steps: [0.001, 0.001]
#   per_batch_size: 25
#   fid_sample_num: 50000