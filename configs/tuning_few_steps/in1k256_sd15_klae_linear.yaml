output_dir: './outputs'

data:
  json_file: './sd_data_2k/captions.json'
  image_size: 512
  image_root_path: './sd_data_2k'
  num_workers: 8
  latent_multiplier: 0.18215
#   data_path: './buffers/data/sdvae_f8c4/train_256'
#   fid_reference_file: './buffers/refs/in1k256_fid_ref.npz'
  
#   num_classes: 1000
#   num_workers: 8
#   latent_norm: False

vae:
  type: 'klae_ema_f8c4'
  downsample_ratio: 8

# model:
#   type: SiT-XL/2
#   in_chans: 4

model:
  pretrained_model_name_or_path: /gpfs/share/home/2301110044/pretrained_models/stable-diffusion-v1-5
  image_encoder_path: /gpfs/share/home/2301110044/pretrained_models/IP-Adapter/models/image_encoder
  pretrained_ip_adapter_path: /gpfs/share/home/2301110044/pretrained_models/IP-Adapter/models/ip-adapter_sd15.bin

train:
  # ckpt: "0000400.pt" # <---- a model trined using "REPA" (https://github.com/sihyun-yu/REPA)
  no_reopt: True
  no_reuni: True
  no_buffer: False
  max_steps: 1
  # max_steps: 1
  # global_batch_size: 32
  global_batch_size: 4
  global_seed: 0
  log_every: 50
  ckpt_every: 1
  ema_decay: 0.99

optimizer:
  type: 'RAdam'
  lr: 0.0001
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.999
  max_grad_norm: 0.1

transport:
  type: DDIM
  lab_drop_ratio: 0.1
  # consistc_ratio: 1.0
  consistc_ratio: 0.0
  enhanced_ratio: 0.0
  enhanced_style: null
  scaled_cbl_eps: 0.0
  ema_decay_rate: 1.0
  enhanced_range: [0.0, 0.75]
  time_dist_ctrl: [1.0, 1.0, 1.0]
  weight_funcion: Cosine
  wt_cosine_loss: False

sample:
  ckpt: "0003200.pt"
  type: UNI
  cfg_scale: 0.0
  cfg_interval: [0.00, 0.70]
  sampling_steps: 2
  stochast_ratio: 1.0
  extrapol_ratio: 0.0
  sampling_order: 1
  time_dist_ctrl: [1.0, 1.0, 1.0]
  rfba_gap_steps: [0.001, 0.60]
  # per_batch_size: 125
  per_batch_size: 50
  fid_sample_num: 50000 # Sample per device = 50000 / 8 = 6250
